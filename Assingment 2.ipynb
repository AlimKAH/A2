{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Assignment 2\n",
    "\n",
    "## Instructions\n",
    "- Your submission should be the `.ipynb` file with your name,\n",
    "  like `YusufMesbah.ipynb`. it should include the answers to the questions in\n",
    "  markdown cells.\n",
    "- You are expected to follow the best practices for code writing and model\n",
    "training. Poor coding style will be penalized.\n",
    "- You are allowed to discuss ideas with your peers, but no sharing of code.\n",
    "Plagiarism in the code will result in failing. If you use code from the\n",
    "internet, cite it.\n",
    "- If the instructions seem vague, use common sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Task 1: ANN (30%)\n",
    "For this task, you are required to build a fully connect feed-forward ANN model\n",
    "for a multi-label regression problem.\n",
    "\n",
    "For the given data, you need do proper data preprocessing, design the ANN model,\n",
    "then fine-tune your model architecture (number of layers, number of neurons,\n",
    "activation function, learning rate, momentum, regularization).\n",
    "\n",
    "For evaluating your model, do $80/20$ train test split.\n",
    "\n",
    "### Data\n",
    "You will be working with the data in `Task 1.csv` for predicting students'\n",
    "scores in 3 different exams: math, reading and writing. The columns include:\n",
    " - gender\n",
    " - race\n",
    " - parental level of education\n",
    " - lunch meal plan at school\n",
    " - whether the student undertook the test preparation course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.19.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-image) (1.9.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-image) (1.23.3)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-image) (2.22.4)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-image) (2022.10.10)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-image) (9.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-image) (21.3)\n",
      "Requirement already satisfied: networkx>=2.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-image) (2.8.8)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from packaging>=20.0->scikit-image) (3.0.9)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.13.0)\n",
      "Requirement already satisfied: torchvision in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.14.0)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torchvision) (1.23.3)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->torchvision) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->torchvision) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->torchvision) (2.1.1)\n",
      "Requirement already satisfied: albumentations in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.3.0)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from albumentations) (4.6.0.66)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from albumentations) (1.9.1)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from albumentations) (0.19.3)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from albumentations) (1.23.3)\n",
      "Requirement already satisfied: qudida>=0.0.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from albumentations) (0.0.4)\n",
      "Requirement already satisfied: PyYAML in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from albumentations) (6.0)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from qudida>=0.0.4->albumentations) (1.1.2)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from qudida>=0.0.4->albumentations) (4.4.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations) (1.4.1)\n",
      "Requirement already satisfied: networkx>=2.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations) (2.8.8)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations) (2022.10.10)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations) (21.3)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations) (2.22.4)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations) (9.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from packaging>=20.0->scikit-image>=0.16.1->albumentations) (3.0.9)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -U scikit-image\n",
    "!pip3 install torch torchvision\n",
    "!pip3 install -U albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race/ethnicity</th>\n",
       "      <th>parental level of education</th>\n",
       "      <th>test preparation course</th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>group A</td>\n",
       "      <td>high school</td>\n",
       "      <td>completed</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>group D</td>\n",
       "      <td>some high school</td>\n",
       "      <td>none</td>\n",
       "      <td>40</td>\n",
       "      <td>59</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>group E</td>\n",
       "      <td>some college</td>\n",
       "      <td>none</td>\n",
       "      <td>59</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>group B</td>\n",
       "      <td>high school</td>\n",
       "      <td>none</td>\n",
       "      <td>77</td>\n",
       "      <td>78</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>group E</td>\n",
       "      <td>associate's degree</td>\n",
       "      <td>completed</td>\n",
       "      <td>78</td>\n",
       "      <td>73</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender race/ethnicity parental level of education test preparation course  \\\n",
       "0    male        group A                 high school               completed   \n",
       "1  female        group D            some high school                    none   \n",
       "2    male        group E                some college                    none   \n",
       "3    male        group B                 high school                    none   \n",
       "4    male        group E          associate's degree               completed   \n",
       "\n",
       "   math score  reading score  writing score  \n",
       "0          67             67             63  \n",
       "1          40             59             55  \n",
       "2          59             60             50  \n",
       "3          77             78             68  \n",
       "4          78             73             68  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Implement task 1\n",
    "\n",
    "df = pd.read_csv('Task 1.csv')\n",
    "\n",
    "df = df.drop(['lunch'], axis=1)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.547945</td>\n",
       "      <td>0.519481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.438356</td>\n",
       "      <td>0.415584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.528736</td>\n",
       "      <td>0.452055</td>\n",
       "      <td>0.350649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.735632</td>\n",
       "      <td>0.698630</td>\n",
       "      <td>0.584416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.747126</td>\n",
       "      <td>0.630137</td>\n",
       "      <td>0.584416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1    2    3         4         5         6\n",
       "0  1.0  0.00  0.4  0.0  0.620690  0.547945  0.519481\n",
       "1  0.0  0.75  1.0  1.0  0.310345  0.438356  0.415584\n",
       "2  1.0  1.00  0.8  1.0  0.528736  0.452055  0.350649\n",
       "3  1.0  0.25  0.4  1.0  0.735632  0.698630  0.584416\n",
       "4  1.0  1.00  0.0  0.0  0.747126  0.630137  0.584416"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert not df.isnull().values.any()\n",
    "\n",
    "df['gender'] = df['gender'].astype('category')\n",
    "df['gender'] = df['gender'].cat.codes\n",
    "\n",
    "df['test preparation course'] = df['test preparation course'].astype('category')\n",
    "df['test preparation course'] = df['test preparation course'].cat.codes\n",
    "\n",
    "df['race/ethnicity'] = df['race/ethnicity'].astype('category')\n",
    "df['race/ethnicity'] = df['race/ethnicity'].cat.codes\n",
    "\n",
    "df['parental level of education'] = df['parental level of education'].astype('category')\n",
    "df['parental level of education'] = df['parental level of education'].cat.codes\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df)\n",
    "df = scaler.transform(df)\n",
    "\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "\n",
    "  def __init__(self, file_name):\n",
    "\n",
    "\n",
    "    x=file_name.iloc[:,0:4].values\n",
    "    y=file_name.iloc[:,4:7].values\n",
    "\n",
    "    self.x_train=torch.tensor(x,dtype=torch.float32)\n",
    "    self.y_train=torch.tensor(y,dtype=torch.float32)\n",
    "\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.y_train)\n",
    "\n",
    "  def __getitem__(self,idx):\n",
    "    return self.x_train[idx],self.y_train[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset = MyDataset(df)\n",
    "# for i, (data, labels) in enumerate(dataset):\n",
    "#     print(data.shape, labels.shape)\n",
    "#     print(data,labels)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size =12, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "class Net(T.nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()\n",
    "    self.hid1 = T.nn.Linear(4, 10)  # 6-(10-10)-3\n",
    "    self.hid2 = T.nn.Linear(10, 20)\n",
    "    self.hid3 = T.nn.Linear(20, 40)\n",
    "    self.hid4 = T.nn.Linear(40, 40)\n",
    "    self.hid5 = T.nn.Linear(40, 10)\n",
    "    self.oupt = T.nn.Linear(10, 3)\n",
    "\n",
    "    T.nn.init.xavier_uniform_(self.hid1.weight)\n",
    "    T.nn.init.zeros_(self.hid1.bias)\n",
    "    T.nn.init.xavier_uniform_(self.hid3.weight)\n",
    "    T.nn.init.zeros_(self.hid3.bias)\n",
    "    T.nn.init.xavier_uniform_(self.hid4.weight)\n",
    "    T.nn.init.zeros_(self.hid4.bias)\n",
    "    T.nn.init.xavier_uniform_(self.hid5.weight)\n",
    "    T.nn.init.zeros_(self.hid5.bias)\n",
    "    T.nn.init.xavier_uniform_(self.hid2.weight)\n",
    "    T.nn.init.zeros_(self.hid2.bias)\n",
    "    T.nn.init.xavier_uniform_(self.oupt.weight) \n",
    "    T.nn.init.zeros_(self.oupt.bias)\n",
    "\n",
    "  def forward(self, x):\n",
    "    z = T.tanh(self.hid1(x))\n",
    "    z = T.tanh(self.hid2(z))\n",
    "    z = T.tanh(self.hid3(z))\n",
    "    z = T.tanh(self.hid4(z))\n",
    "    z = T.sigmoid(self.hid5(z))\n",
    "    z = T.sigmoid(self.oupt(z))  # assumes CrossEntropyLoss()\n",
    "    return z\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim, nn\n",
    "net = Net()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "epoch = 10\n",
    "loss_list = []\n",
    "accuracy_list = []\n",
    "iteration_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (4.64.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "def train(epoch):\n",
    "    i = 0\n",
    "    for features, labels in tqdm(train_loader):\n",
    "        features, labels = Variable(features), Variable(labels)\n",
    "\n",
    "        # zero out gradients from previous iteration\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward propagation\n",
    "        output = net(features)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        # backprop\n",
    "        loss.backward()\n",
    "        \n",
    "        # update params (gradient descent)\n",
    "        optimizer.step()\n",
    "            \n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "def evaluate(data_loader):\n",
    "    net.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for features, labels in data_loader:\n",
    "        with torch.no_grad():\n",
    "            features, labels = Variable(features), Variable(labels)\n",
    "            output = net(features)\n",
    "            \n",
    "        loss += F.cross_entropy(output, labels, size_average=False).data.item()\n",
    "        pred = output.data.max(1, keepdim=True)\n",
    "        correct += pred.eq(labels.data.view_as(pred))\n",
    "        \n",
    "        \n",
    "    loss /= len(data_loader.dataset)\n",
    "    accuracy = 100. * correct / len(data_loader.dataset)\n",
    "    print('Epoch: {}, Average loss: {:.4f}, Accuracy: {}/{} ({:.3f}%)'.format(\n",
    "        epoch,\n",
    "        loss, correct, len(data_loader.dataset),\n",
    "        accuracy))\n",
    "    loss_list.append(loss)\n",
    "    accuracy_list.append(accuracy)\n",
    "    iteration_list.append(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [00:00<00:00, 1987.32it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2321.39it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2423.82it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2385.22it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2332.82it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2423.20it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2410.96it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2402.81it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2456.28it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2431.67it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2379.67it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2431.75it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2472.03it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2414.22it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2432.87it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2459.18it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2466.32it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2439.16it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2368.93it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2466.39it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2482.48it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2462.55it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2445.62it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2440.22it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2430.27it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2442.57it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2035.59it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2409.48it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2455.36it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2495.69it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2467.89it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2440.81it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2500.37it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2443.79it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2515.86it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2482.57it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2475.56it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2499.92it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2471.03it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2482.48it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2483.60it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2451.68it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2470.01it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2495.76it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2489.25it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2474.17it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2463.70it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2479.83it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2412.14it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2473.56it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2475.32it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2430.19it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2473.21it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2462.19it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2488.45it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2482.71it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2464.70it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2479.48it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2486.83it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2491.54it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2460.33it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2462.05it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2497.10it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2444.33it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2479.86it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2386.58it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2368.33it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2320.78it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2170.14it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2168.64it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2257.27it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 1925.50it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2259.70it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2177.58it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2219.33it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2207.33it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2169.31it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2432.25it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2451.77it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2448.56it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2488.88it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2415.96it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2457.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 0.0000, 0.4000, 0.0000]) tensor([0.5067, 0.3886, 0.3921])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 83\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train(epoch)\n",
    "\n",
    "\n",
    "for features, labels in train_loader:\n",
    "    with torch.no_grad():\n",
    "        features, labels = Variable(features), Variable(labels)\n",
    "        output = net(features)\n",
    "        print(features[0], output[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Questions\n",
    "1. What preprocessing techniques did you use? Why?\n",
    "    - *Answer*\n",
    "2. Describe the fine-tuning process and how you reached your model architecture.\n",
    "    - *Answer*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Task 2: CNN (40%)\n",
    "For this task, you will be doing image classification:\n",
    "- First, adapt your best model from Task 1 to work on this task, and\n",
    "fit it on the new data. Then, evaluate its performance.\n",
    "- After that, build a CNN model for image classification.\n",
    "- Compare both models in terms of accuracy, number of parameters and speed of\n",
    "inference (the time the model takes to predict 50 samples).\n",
    "\n",
    "For the given data, you need to do proper data preprocessing and augmentation,\n",
    "data loaders.\n",
    "Then fine-tune your model architecture (number of layers, number of filters,\n",
    "activation function, learning rate, momentum, regularization).\n",
    "\n",
    "### Data\n",
    "You will be working with the data in `triple_mnist.zip` for predicting 3-digit\n",
    "numbers writen in the image. Each image contains 3 digits similar to the\n",
    "following example (whose label is `039`):\n",
    "\n",
    "![example](https://github.com/shaohua0116/MultiDigitMNIST/blob/master/asset/examples/039/0_039.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Implement task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Questions\n",
    "1. What preprocessing techniques did you use? Why?\n",
    "    - *Answer*\n",
    "2. What data augmentation techniques did you use?\n",
    "    - *Answer*\n",
    "3. Describe the fine-tuning process and how you reached your final CNN model.\n",
    "    - *Answer*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Task 3: Decision Trees and Ensemble Learning (15%)\n",
    "\n",
    "For the `loan_data.csv` data, predict if the bank should give a loan or not.\n",
    "You need to do the following:\n",
    "- Fine-tune a decision tree on the data\n",
    "- Fine-tune a random forest on the data\n",
    "- Compare their performance\n",
    "- Visualize your DT and one of the trees from the RF\n",
    "\n",
    "For evaluating your models, do $80/20$ train test split.\n",
    "\n",
    "### Data\n",
    "- `credit.policy`: Whether the customer meets the credit underwriting criteria.\n",
    "- `purpose`: The purpose of the loan.\n",
    "- `int.rate`: The interest rate of the loan.\n",
    "- `installment`: The monthly installments owed by the borrower if the loan is funded.\n",
    "- `log.annual.inc`: The natural logarithm of the self-reported annual income of the borrower.\n",
    "- `dti`: The debt-to-income ratio of the borrower.\n",
    "- `fico`: The FICO credit score of the borrower.\n",
    "- `days.with.cr.line`: The number of days the borrower has had a credit line.\n",
    "- `revol.bal`: The borrower's revolving balance.\n",
    "- `revol.util`: The borrower's revolving line utilization rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Implement task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Questions\n",
    "1. How did the DT compare to the RF in performance? Why?\n",
    "    - *Answer*\n",
    "2. After fine-tuning, how does the max depth in DT compare to RF? Why?\n",
    "    - *Answer*\n",
    "3. What is ensemble learning? What are its pros and cons?\n",
    "    - *Answer*\n",
    "4. Briefly explain 2 types of boosting methods and 2 types of bagging methods.\n",
    "Which of these categories does RF fall under?\n",
    "    - *Answer*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Task 4: Domain Gap (15%)\n",
    "\n",
    "Evaluate your CNN model from task 2 on SVHN data without retraining your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Implement task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Questions\n",
    "1. How did your model perform? Why is it better/worse?\n",
    "    - *Answer*\n",
    "2. What is domain gap in the context of ML?\n",
    "    - *Answer*\n",
    "3. Suggest two ways through which the problem of domain gap can be tackled.\n",
    "    - *Answer*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
